/********** Begin **********/
--********** create student database **********--
create database student on primary
(
    name='studentdata1',
    filename='/home/studentdata1.mdf',
    size=5MB,
    maxsize=10MB,
    filegrowth=1MB
),
(
    name='studentdata2',
    filename='/home/studentdata2.ndf',
    size=5MB,
    maxsize=10MB,
    filegrowth=1MB
)
log on
(
    name='studentlog1',
    filename='/home/studentlog1.ldf',
    size=5MB,
    maxsize=10MB,
    filegrowth=1MB
);
--********** create end **********--
go

--********** add database file **********--
alter database student add file
(
    name='studentdata3',
    filename='/home/studentdata3.ndf',
    size=6MB,
    maxsize=20MB,
    filegrowth=1MB
);
--********** add file end **********--
go

--********** add database log file **********--
alter database student add log file
(
    name='studentlog2',
    filename='/home/studentlog2.ldf',
    size=6MB,
    maxsize=20MB,
    filegrowth=1MB
);

--********** add log file end **********--
go

--********** alter database file **********--
alter database student modify file
(
    name='studentdata3',
    size=8MB,
    maxsize=30MB
);

--********** alter end **********--
go
/********** End **********/
















USE studentdb
go

SET NOCOUNT ON 
go
/********** Begin **********/
--********** create begin **********--
CREATE TABLE Student
(
    sno varchar(50),
    name varchar(50),
    sex varchar(10),
    birthday Date,
    discipline varchar(50),
    school varchar(100)
);

CREATE TABLE Course
(
    cno varchar(50),
    cname varchar(50),
    description varchar(256),
    credit float,
    cinstitution varchar(128)
);

CREATE TABLE Score
(
    sno varchar(50),
    cno varchar(50),
    grade float
);


--********** create end **********--
go
select name, length, COLLATION from syscolumns where id=object_Id('student')
go
select name, length, COLLATION from syscolumns where id=object_Id('course')
go
select name, length, COLLATION from syscolumns where id=object_Id('score')
go


--********** insert begin **********--
INSERT INTO Score (sno, cno, grade) VALUES ('09011101', '101', 89);
INSERT INTO Score (sno, cno, grade) VALUES ('09011101', '102', 78);


--********** insert end **********--
select * from  score
go


--********** alt student table **********--
ALTER TABLE Student
ADD addr varchar(256);


--********** alt end **********--
go

select name, length, COLLATION from syscolumns where id=object_Id('student')
go

--********** del score table **********--
DROP TABLE Score;


--********** del end **********--
/********** End **********/

GO
IF NOT EXISTS(Select 1 From Sysobjects Where Name='score')  --查询表是否存在
BEGIN
PRINT 'NOT EXISTS TABLE score'
END
GO



（第二关）
USE studentdb
go

SET NOCOUNT ON 
go
/********** Begin **********/
--********** create score_view_cdept **********--
CREATE VIEW score_view_cdept AS
SELECT s.sno, s.name, c.cname, sc.grade
FROM Student s
JOIN Score sc ON s.sno = sc.sno
JOIN Course c ON sc.cno = c.cno;

--********** create end **********--
/********** End **********/
go






"""
(第一关）
"""
def load_Lksub1():

    Lksub1 = [frozenset(['l2', 'l3']),
             frozenset(['l1', 'l3']),frozenset(['l2', 'l1']),frozenset(['l2', 'l5'])]
    return Lksub1

def load_Ck_item1():

   Ck_item = frozenset(['l1', 'l2', 'l3'])
   return Ck_item
   
def load_Ck_item2():

   Ck_item = frozenset(['l1', 'l2', 'l5'])
   return Ck_item


def is_apriori(Ck_item, Lksub1):
"""
  判断频繁的候选k项目集是否满足Apriori属性；
  Ck_item：Ck中的一个频繁候选k-itemset，其中包含所有频繁候选k项集；
  Lksub1：Lk-1，一个包含所有频繁候选（k-1）个项目集的集合；
  满足Apriori属性返回True；
  不满足Apriori属性返回False。
"""
   #******* Begin *******#
# 遍历Ck_item的所有(k-1)项子集
    for i in range(1, len(Ck_item)):
        # 生成(k-1)项子集
        for k_1_set in get_k_1_combinations(Ck_item, i):
            # 如果(k-1)项子集不在Lksub1中，则不满足Apriori属性
            if k_1_set not in Lksub1:
                return False
    # 所有(k-1)项子集都在Lksub1中，则满足Apriori属性
    return True

def get_k_1_combinations(itemset, k):
    """
    生成itemset中所有(k-1)项子集
    """
    from itertools import combinations
    return set(map(frozenset, combinations(itemset, k)))

   #******** End ********#
  

if __name__ == "__main__":

    Ck_item1 = load_Ck_item1()
    Ck_item2 = load_Ck_item2()
    Lksub1 = load_Lksub1()
    if is_apriori(Ck_item1,Lksub1) :
      print ("true")
    else:
      print ("false")
      
    if is_apriori(Ck_item2,Lksub1) :
      print ("true")
    else:
      print ("false")



"""
(第二关）
"""
#coding=utf-8
def load_data_set():
    """
    Load a sample data set (From Data Mining: Concepts and Techniques, 3th Edition)
    Returns: 
        A data set: A list of transactions. Each transaction contains several items.
    """
    data_set = [['beer', 'milk', 'chicken'], ['milk', 'bread'], ['milk', 'diaper'],
            ['beer', 'milk', 'bread'], ['beer', 'diaper'], ['milk', 'diaper'],
            ['beer', 'diaper'], ['beer', 'milk', 'diaper', 'chicken'], ['beer', 'milk', 'diaper']]
    return data_set


def load_support_data():
    """
    Load a sample data set (From Data Mining: Concepts and Techniques, 3th Edition)
    Returns: 
        A data set: A list of transactions. Each transaction contains several items.
    """
    support_data = {frozenset({'chicken'}): 0.2222222222222222, frozenset({'milk'}): 0.7777777777777778, frozenset({'beer'}): 0.6666666666666666, frozenset({'bread'}): 0.2222222222222222, frozenset({'diaper'}): 0.6666666666666666}
    return support_data


def load_C2():

    C2 = {frozenset({'diaper', 'chicken'}), frozenset({'chicken', 'bread'}), frozenset({'chicken', 'milk'}), frozenset({'diaper', 'bread'}), frozenset({'beer', 'bread'}), frozenset({'milk', 'bread'}), frozenset({'diaper', 'beer'}), frozenset({'diaper', 'milk'}), frozenset({'beer', 'milk'}), frozenset({'chicken', 'beer'})}
    return C2



def create_Ck(Lksub1, k):
    """
    通过Lk-1自己的连接操作,创建一个包含所有频繁出现的候选k个项集的集合Ck；
    Lksub1：Lk-1，一个包含所有频繁候选（k-1）个项目集的集合；
    k：频繁项目集的项目编号；
    返回：Ck；
    请补全代码。
    """
    Ck = set()
    len_Lksub1 = len(Lksub1)
    list_Lksub1 = list(Lksub1)
    for i in range(len_Lksub1):
        for j in range(1, len_Lksub1):
            l1 = list(list_Lksub1[i])
            l2 = list(list_Lksub1[j])
            l1.sort()
            l2.sort()
               #******* Begin *******#
            if l1[:-1] == l2[:-1]:  # 如果前k-2项相同，则连接
                candidate = frozenset(l1[:-1] + l2[-1:])  # 连接操作
                if is_apriori(candidate, Lksub1):  # 检查是否满足Apriori属性
                    Ck.add(candidate)  

               #******** End ********#
    return Ck


def generate_Lk_by_Ck(data_set, Ck, min_support, support_data):
    """
    Generate Lk by executing a delete policy from Ck.
    Args:
        data_set: A list of transactions. Each transaction contains several items.
        Ck: A set which contains all all frequent candidate k-itemsets.
        min_support: The minimum support.
        support_data: A dictionary. The key is frequent itemset and the value is support.
    Returns:
        Lk: A set which contains all all frequent k-itemsets.
    """
    Lk = set()
    item_count = {}
    for t in data_set:
        for item in Ck:
            if item.issubset(t):
                if item not in item_count:
                    item_count[item] = 1
                else:
                    item_count[item] += 1
    t_num = float(len(data_set))
    """
    判断频繁项集的支持度计数是否大于等于最小支持度数，
    若大于等于最小支持数将该项集加入Lk;
    并将该项集的支持度计数保存至support_data();
    注：频繁项集的支持度计数=项集出现次数/总项集的个数。
    """
      #******* Begin *******#
    for item in item_count:
        support = item_count[item] / t_num
        if support >= min_support:
            Lk.add(item)
            support_data[item] = support

      #******** End ********#   
    return Lk

if __name__ == "__main__":
   data_set=load_data_set()
   C2=load_C2()
   support_data = load_support_data()
   L2 = generate_Lk_by_Ck(data_set, C2, 0.2, support_data)
   temp1=list()
   for freq_set in L2:
            temp=list(freq_set)
            temp.sort()
            temp1.append(temp)
            #print (freq_set, support_data[freq_set])
   temp1.sort()
   for s in temp1:
     print (s, support_data[frozenset(s)])




"""
(第三关）
"""
#coding:gbk

def load_data_set():
    """
    Load a sample data set (From Data Mining: Concepts and Techniques, 3th Edition)
    Returns: 
        A data set: A list of transactions. Each transaction contains several items.
    """
    data_set = [['beer', 'milk', 'chicken'], ['milk', 'bread'], ['milk', 'diaper'],
            ['beer', 'milk', 'bread'], ['beer', 'diaper'], ['milk', 'diaper'],
            ['beer', 'diaper'], ['beer', 'milk', 'diaper', 'chicken'], ['beer', 'milk', 'diaper']]
    return data_set


def create_C1(data_set):
    """
    Create frequent candidate 1-itemset C1 by scaning data set.
    Args:
        data_set: A list of transactions. Each transaction contains several items.
    Returns:
        C1: A set which contains all frequent candidate 1-itemsets
    """
    C1 = set()
    for t in data_set:
        for item in t:
            item_set = frozenset([item])
            C1.add(item_set)
    return C1


def is_apriori(Ck_item, Lksub1):
    """
    Judge whether a frequent candidate k-itemset satisfy Apriori property.
    Args:
        Ck_item: a frequent candidate k-itemset in Ck which contains all frequent
                 candidate k-itemsets.
        Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.
    Returns:
        True: satisfying Apriori property.
        False: Not satisfying Apriori property.
    """
    for item in Ck_item:
        sub_Ck = Ck_item - frozenset([item])
        if sub_Ck not in Lksub1:
            return False
    return True


def create_Ck(Lksub1, k):
    """
    Create Ck, a set which contains all all frequent candidate k-itemsets
    by Lk-1's own connection operation.
    Args:
        Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.
        k: the item number of a frequent itemset.
    Return:
        Ck: a set which contains all all frequent candidate k-itemsets.
    """
    Ck = set()
    len_Lksub1 = len(Lksub1)
    list_Lksub1 = list(Lksub1)
    for i in range(len_Lksub1):
        for j in range(1, len_Lksub1):
            l1 = list(list_Lksub1[i])
            l2 = list(list_Lksub1[j])
            l1.sort()
            l2.sort()
            if l1[0:k-2] == l2[0:k-2]:
                Ck_item = list_Lksub1[i] | list_Lksub1[j]
                # pruning
               #3
                if is_apriori(Ck_item, Lksub1):
                    Ck.add(Ck_item)
    return Ck


def generate_Lk_by_Ck(data_set, Ck, min_support, support_data):
    """
    Generate Lk by executing a delete policy from Ck.
    Args:
        data_set: A list of transactions. Each transaction contains several items.
        Ck: A set which contains all all frequent candidate k-itemsets.
        min_support: The minimum support.
        support_data: A dictionary. The key is frequent itemset and the value is support.
    Returns:
        Lk: A set which contains all all frequent k-itemsets.
    """
    Lk = set()
    item_count = {}
    for t in data_set:
        for item in Ck:
            if item.issubset(t):
                if item not in item_count:
                    item_count[item] = 1
                else:
                    item_count[item] += 1
    t_num = float(len(data_set))
    for item in item_count:
        #2
        if (item_count[item] / t_num) >= min_support:
            Lk.add(item)
            #1
            support_data[item] = item_count[item] / t_num
    return Lk


def generate_L(data_set, k, min_support):
    """
    Generate all frequent itemsets.
    Args:
        data_set: A list of transactions. Each transaction contains several items.
        k: Maximum number of items for all frequent itemsets.
        min_support: The minimum support.
    Returns:
        L: The list of Lk.
        support_data: A dictionary. The key is frequent itemset and the value is support.
    """
    support_data = {}
    C1 = create_C1(data_set)
    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)
    Lksub1 = L1.copy()
    L = []
    L.append(Lksub1)
    for i in range(2, k+1):
        #**********Begin**********#
        Ck = create_Ck(Lksub1, i)  # Create Ck
        Lk = generate_Lk_by_Ck(data_set, Ck, min_support, support_data)  # Generate Lk
        if len(Lk) == 0:  # If Lk is empty, break the loop
            break
        L.append(Lk)
        Lksub1 = Lk.copy()  # Update Lksub1 for the next iteration           
               
               
                 
        #***********End***********#
    return L, support_data


def generate_big_rules(L, support_data, min_conf):
    """
    Generate big rules from frequent itemsets.
    Args:
        L: The list of Lk.
        support_data: A dictionary. The key is frequent itemset and the value is support.
        min_conf: Minimal confidence.
    Returns:
        big_rule_list: A list which contains all big rules. Each big rule is represented
                       as a 3-tuple .
    """
    big_rule_list = []
    sub_set_list = []
    for i in range(0, len(L)):
        for freq_set in L[i]:
            for sub_set in sub_set_list:
               #**********Begin**********#
                if sub_set.issubset(freq_set):  # If the subset is a subset of the current freq_set
                    result_set = freq_set - sub_set  # Find the result set (freq_set - sub_set)
                    if len(result_set) > 0:  # If the result set is not empty
                        conf = support_data[freq_set] / support_data[sub_set]  # Calculate confidence
                        if conf >= min_conf:  # If confidence is greater than or equal to min_conf
                            big_rule_list.append((sub_set, result_set, conf))  # Add the rule to the list   
               
               
               
               
               
               #***********End***********#
            sub_set_list.append(freq_set)
    return big_rule_list


if __name__ == "__main__":
    """
    Test
    """
    data_set = load_data_set()
    L, support_data = generate_L(data_set, k=3, min_support=0.2)
    big_rules_list = generate_big_rules(L, support_data, min_conf=0.7)
    for Lk in L:
        #LKlist=sorted(list(Lk),key= lambda i:i[0])
        print ("="*50)
        print ("frequent " + str(len(list(Lk)[0])) + "-itemsets\t\tsupport")
        print ("="*50)
        temp1=list()
        for freq_set in Lk:
            temp=list(freq_set)
            temp.sort()
            temp1.append(temp)
            #print (freq_set, support_data[freq_set])
        temp1.sort()
        for s in temp1:
          print (s, support_data[frozenset(s)])
    print ("Big Rules")
    temp1=list()
    for item in big_rules_list:
        temp=list(item[0])
        temp.sort()
        if temp not in temp1:
           temp1.append(temp)
    temp1.sort()
    for t in temp1:
        count=0
        tempset=set()
        for item in big_rules_list:
            #
            if item[0]==frozenset(t):
                count+=1
                tempset.add(item)
        if count==1 :
           for item in big_rules_list:
            #
             if item[0]==frozenset(t):
               list0=list(item[0])
               list0.sort()
               print (list0, "=>", list(item[1]), "conf: ", item[2])
        else :
           temp2=list()
           for item in tempset:
              temp=list(item[1])
              temp.sort()
              if temp not in temp2:
                temp2.append(temp)
           temp2.sort()
           for a in temp2:
              for item in tempset:
                if item[1]==frozenset(a):
                  list0=list(item[1])
                  list0.sort()
                  print (list(item[0]), "=>", list0, "conf: ", item[2])





















